{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet 'Billboard 200' combined data saved to '../../data/beema/combined_data_beema\\Billboard 200_combined.csv'.\n",
      "Sheet 'Heatseekers' combined data saved to '../../data/beema/combined_data_beema\\Heatseekers_combined.csv'.\n",
      "Sheet 'Top 200 Song Consumption' combined data saved to '../../data/beema/combined_data_beema\\Top 200 Song Consumption_combined.csv'.\n",
      "Sheet 'Video On-Demand Streaming' combined data saved to '../../data/beema/combined_data_beema\\Video On-Demand Streaming_combined.csv'.\n",
      "Sheet 'Current Country Albums' combined data saved to '../../data/beema/combined_data_beema\\Current Country Albums_combined.csv'.\n",
      "Sheet 'Country Airplay' combined data saved to '../../data/beema/combined_data_beema\\Country Airplay_combined.csv'.\n",
      "Sheet 'Country On-Demand Streaming' combined data saved to '../../data/beema/combined_data_beema\\Country On-Demand Streaming_combined.csv'.\n",
      "Sheet 'Current Rock Albums' combined data saved to '../../data/beema/combined_data_beema\\Current Rock Albums_combined.csv'.\n",
      "Sheet 'Rock Airplay' combined data saved to '../../data/beema/combined_data_beema\\Rock Airplay_combined.csv'.\n",
      "Sheet 'Rock On-Demand Streaming' combined data saved to '../../data/beema/combined_data_beema\\Rock On-Demand Streaming_combined.csv'.\n",
      "Sheet 'Current Pop Albums' combined data saved to '../../data/beema/combined_data_beema\\Current Pop Albums_combined.csv'.\n",
      "Sheet 'Top 40 Airplay' combined data saved to '../../data/beema/combined_data_beema\\Top 40 Airplay_combined.csv'.\n",
      "Sheet 'Pop On-Demand Streaming' combined data saved to '../../data/beema/combined_data_beema\\Pop On-Demand Streaming_combined.csv'.\n",
      "Sheet 'Current Rap Albums' combined data saved to '../../data/beema/combined_data_beema\\Current Rap Albums_combined.csv'.\n",
      "Sheet 'Current R&B Hip Hop Albums' combined data saved to '../../data/beema/combined_data_beema\\Current R&B Hip Hop Albums_combined.csv'.\n",
      "Sheet 'R&B Hip Hop Airplay' combined data saved to '../../data/beema/combined_data_beema\\R&B Hip Hop Airplay_combined.csv'.\n",
      "Sheet 'R&B Hip Hop On-Demand Streaming' combined data saved to '../../data/beema/combined_data_beema\\R&B Hip Hop On-Demand Streaming_combined.csv'.\n",
      "Sheet 'Dance Electronic On-Demand' combined data saved to '../../data/beema/combined_data_beema\\Dance Electronic On-Demand_combined.csv'.\n",
      "Sheet 'R&B Hip Hop Albums' combined data saved to '../../data/beema/combined_data_beema\\R&B Hip Hop Albums_combined.csv'.\n",
      "Sheet ' Heatseekers' combined data saved to '../../data/beema/combined_data_beema\\ Heatseekers_combined.csv'.\n",
      "Sheet 'Dance Electronic On-Demand ' combined data saved to '../../data/beema/combined_data_beema\\Dance Electronic On-Demand _combined.csv'.\n",
      "Sheet 'R&B Hip Hop on-Demand Streaming' combined data saved to '../../data/beema/combined_data_beema\\R&B Hip Hop on-Demand Streaming_combined.csv'.\n"
     ]
    }
   ],
   "source": [
    "## Convert individual excel files into individual csv files (by sheet name/Billboard chart type) for analysis\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def combine_sheets_across_excels(source_folder, output_folder):\n",
    "    # Dictionary to hold dataframes for each sheet name\n",
    "    # Key: sheet_name, Value: list of dataframes from all files for that sheet\n",
    "    sheets_dict = {}\n",
    "\n",
    "    # Iterate over all files in the source folder\n",
    "    for filename in os.listdir(source_folder):\n",
    "        if filename.endswith('.xlsx'):\n",
    "            # Construct full file path\n",
    "            excel_path = os.path.join(source_folder, filename)\n",
    "\n",
    "            # Extract a date from filenames (if applicable)\n",
    "            # Adjust this logic based on how your filenames are structured\n",
    "            date_str = filename.replace('Week of ', '').replace('.xlsx', '').strip()\n",
    "\n",
    "            # Load the Excel file\n",
    "            xls = pd.ExcelFile(excel_path)\n",
    "            \n",
    "            # Iterate through each sheet in the Excel file\n",
    "            for sheet_name in xls.sheet_names:\n",
    "                # Read the specific sheet\n",
    "                df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "                \n",
    "                # Add columns to distinguish this data\n",
    "                df['week_of'] = date_str\n",
    "\n",
    "                # Append this dataframe to the list for the given sheet_name\n",
    "                if sheet_name not in sheets_dict:\n",
    "                    sheets_dict[sheet_name] = []\n",
    "                sheets_dict[sheet_name].append(df)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Now combine each sheet's DataFrames and save to CSV\n",
    "    for sheet_name, df_list in sheets_dict.items():\n",
    "        combined_df = pd.concat(df_list, ignore_index=True)\n",
    "        \n",
    "        # Construct output CSV filename\n",
    "        csv_filename = f\"{sheet_name}_combined.csv\"\n",
    "        output_csv_path = os.path.join(output_folder, csv_filename)\n",
    "\n",
    "        # Save the combined dataframe to a CSV file\n",
    "        combined_df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Sheet '{sheet_name}' combined data saved to '{output_csv_path}'.\")\n",
    "\n",
    "# Usage:\n",
    "source_folder = \"../../data/beema/raw_data_beema\"\n",
    "output_folder = \"../../data/beema/combined_data_beema\"\n",
    "\n",
    "combine_sheets_across_excels(source_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Heatseekers_combined.csv\n",
      "Billboard 200_combined.csv\n",
      "Country Airplay_combined.csv\n",
      "Country On-Demand Streaming_combined.csv\n",
      "Current Country Albums_combined.csv\n",
      "Current Pop Albums_combined.csv\n",
      "Current R&B Hip Hop Albums_combined.csv\n",
      "Current Rap Albums_combined.csv\n",
      "Current Rock Albums_combined.csv\n",
      "Dance Electronic On-Demand _combined.csv\n",
      "Dance Electronic On-Demand_combined.csv\n",
      "Heatseekers_combined.csv\n",
      "Pop On-Demand Streaming_combined.csv\n",
      "R&B Hip Hop Airplay_combined.csv\n",
      "R&B Hip Hop Albums_combined.csv\n",
      "R&B Hip Hop On-Demand Streaming_combined.csv\n",
      "Rock Airplay_combined.csv\n",
      "Rock On-Demand Streaming_combined.csv\n",
      "Top 200 Song Consumption_combined.csv\n",
      "Top 40 Airplay_combined.csv\n",
      "Video On-Demand Streaming_combined.csv\n",
      "Renamed:  Heatseekers_combined.csv -> _heatseekers_combined.csv\n",
      "Renamed: Billboard 200_combined.csv -> billboard_200_combined.csv\n",
      "Renamed: Country Airplay_combined.csv -> country_airplay_combined.csv\n",
      "Renamed: Country On-Demand Streaming_combined.csv -> country_on-demand_streaming_combined.csv\n",
      "Renamed: Current Country Albums_combined.csv -> current_country_albums_combined.csv\n",
      "Renamed: Current Pop Albums_combined.csv -> current_pop_albums_combined.csv\n",
      "Renamed: Current R&B Hip Hop Albums_combined.csv -> current_r&b_hip_hop_albums_combined.csv\n",
      "Renamed: Current Rap Albums_combined.csv -> current_rap_albums_combined.csv\n",
      "Renamed: Current Rock Albums_combined.csv -> current_rock_albums_combined.csv\n",
      "Renamed: Dance Electronic On-Demand _combined.csv -> dance_electronic_on-demand__combined.csv\n",
      "Renamed: Dance Electronic On-Demand_combined.csv -> dance_electronic_on-demand_combined.csv\n",
      "Renamed: Heatseekers_combined.csv -> heatseekers_combined.csv\n",
      "Renamed: Pop On-Demand Streaming_combined.csv -> pop_on-demand_streaming_combined.csv\n",
      "Renamed: R&B Hip Hop Airplay_combined.csv -> r&b_hip_hop_airplay_combined.csv\n",
      "Renamed: R&B Hip Hop Albums_combined.csv -> r&b_hip_hop_albums_combined.csv\n",
      "Renamed: R&B Hip Hop On-Demand Streaming_combined.csv -> r&b_hip_hop_on-demand_streaming_combined.csv\n",
      "Renamed: Rock Airplay_combined.csv -> rock_airplay_combined.csv\n",
      "Renamed: Rock On-Demand Streaming_combined.csv -> rock_on-demand_streaming_combined.csv\n",
      "Renamed: Top 200 Song Consumption_combined.csv -> top_200_song_consumption_combined.csv\n",
      "Renamed: Top 40 Airplay_combined.csv -> top_40_airplay_combined.csv\n",
      "Renamed: Video On-Demand Streaming_combined.csv -> video_on-demand_streaming_combined.csv\n"
     ]
    }
   ],
   "source": [
    "## Some of the data has different names but are for the same data\n",
    "\n",
    "# Fixing first naming issue:\n",
    "\n",
    "def rename_files_to_lowercase_and_replace_spaces(folder_path):\n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Construct the old file path\n",
    "        old_file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Skip if it's not a file\n",
    "        if not os.path.isfile(old_file_path):\n",
    "            continue\n",
    "\n",
    "        # Create the new filename: lowercase and replace spaces with underscores\n",
    "        new_filename = filename.lower().replace(\" \", \"_\")\n",
    "\n",
    "        # Construct the new file path\n",
    "        new_file_path = os.path.join(folder_path, new_filename)\n",
    "\n",
    "        # Rename the file\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "        print(f\"Renamed: {filename} -> {new_filename}\")\n",
    "\n",
    "# Usage\n",
    "folder = \"../../data/beema/combined_data_beema\"\n",
    "rename_files_to_lowercase_and_replace_spaces(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "billboard_200_combined.csv\n",
      "country_airplay_combined.csv\n",
      "country_on-demand_streaming_combined.csv\n",
      "current_country_albums_combined.csv\n",
      "current_pop_albums_combined.csv\n",
      "current_r&b_hip_hop_albums_combined.csv\n",
      "current_rap_albums_combined.csv\n",
      "current_rock_albums_combined.csv\n",
      "dance_electronic_on-demand_combined.csv\n",
      "dance_electronic_on-demand__combined.csv\n",
      "heatseekers_combined.csv\n",
      "pop_on-demand_streaming_combined.csv\n",
      "r&b_hip_hop_airplay_combined.csv\n",
      "r&b_hip_hop_albums_combined.csv\n",
      "r&b_hip_hop_on-demand_streaming_combined.csv\n",
      "rock_airplay_combined.csv\n",
      "rock_on-demand_streaming_combined.csv\n",
      "top_200_song_consumption_combined.csv\n",
      "top_40_airplay_combined.csv\n",
      "video_on-demand_streaming_combined.csv\n",
      "_heatseekers_combined.csv\n"
     ]
    }
   ],
   "source": [
    "folder = \"../../data/beema/combined_data_beema\"\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining 'dance_electronic_on-demand_combined.csv' and 'dance_electronic_on-demand__combined.csv'...\n",
      "Combined data saved to 'dance_electronic_on-demand_combined.csv'.\n",
      "Deleted 'dance_electronic_on-demand__combined.csv'.\n",
      "\n",
      "Combining 'heatseekers_combined.csv' and '_heatseekers_combined.csv'...\n",
      "Combined data saved to 'heatseekers_combined.csv'.\n",
      "Deleted '_heatseekers_combined.csv'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fixing issue:\n",
    "\n",
    "def combine_and_clean_files(folder_path, file_pairs):\n",
    "    for pair in file_pairs:\n",
    "        file1, file2 = pair\n",
    "\n",
    "        # Construct full file paths\n",
    "        file1_path = os.path.join(folder_path, file1)\n",
    "        file2_path = os.path.join(folder_path, file2)\n",
    "\n",
    "        # Check if both files exist\n",
    "        if os.path.exists(file1_path) and os.path.exists(file2_path):\n",
    "            print(f\"Combining '{file1}' and '{file2}'...\")\n",
    "            \n",
    "            # Read both files into DataFrames\n",
    "            df1 = pd.read_csv(file1_path)\n",
    "            df2 = pd.read_csv(file2_path)\n",
    "\n",
    "            # Combine the DataFrames\n",
    "            combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "            # Determine the output filename (use the name of the first file as the base)\n",
    "            output_file_path = file1_path\n",
    "\n",
    "            # Save the combined DataFrame\n",
    "            combined_df.to_csv(output_file_path, index=False)\n",
    "            print(f\"Combined data saved to '{file1}'.\")\n",
    "\n",
    "            # Delete the second file\n",
    "            os.remove(file2_path)\n",
    "            print(f\"Deleted '{file2}'.\\n\")\n",
    "        else:\n",
    "            print(f\"One or both files in pair '{pair}' do not exist. Skipping...\\n\")\n",
    "\n",
    "# Define the folder path and file pairs to combine\n",
    "folder_path = \"../../data/beema/combined_data_beema\"\n",
    "file_pairs = [\n",
    "    (\"dance_electronic_on-demand_combined.csv\", \"dance_electronic_on-demand__combined.csv\"),\n",
    "    (\"heatseekers_combined.csv\", \"_heatseekers_combined.csv\")\n",
    "]\n",
    "\n",
    "combine_and_clean_files(folder_path, file_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\billboard_200_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\country_airplay_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\country_on-demand_streaming_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\current_country_albums_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\current_pop_albums_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\current_r&b_hip_hop_albums_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\current_rap_albums_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\current_rock_albums_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\dance_electronic_on-demand_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\heatseekers_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\pop_on-demand_streaming_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\r&b_hip_hop_airplay_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\r&b_hip_hop_albums_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\r&b_hip_hop_on-demand_streaming_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\rock_airplay_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\rock_on-demand_streaming_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\top_200_song_consumption_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\top_40_airplay_cleaned.csv\n",
      "Cleaned file saved: ../../data/beema/cleaned_data_beema\\video_on-demand_streaming_cleaned.csv\n",
      "\n",
      "Row Changes Summary:\n",
      "billboard_200_combined.csv: 14544 -> 14400 rows (change: -144)\n",
      "country_airplay_combined.csv: 14898 -> 14754 rows (change: -144)\n",
      "country_on-demand_streaming_combined.csv: 14544 -> 14400 rows (change: -144)\n",
      "current_country_albums_combined.csv: 5556 -> 5412 rows (change: -144)\n",
      "current_pop_albums_combined.csv: 7391 -> 7247 rows (change: -144)\n",
      "current_r&b_hip_hop_albums_combined.csv: 14421 -> 14279 rows (change: -142)\n",
      "current_rap_albums_combined.csv: 7447 -> 7303 rows (change: -144)\n",
      "current_rock_albums_combined.csv: 3746 -> 3602 rows (change: -144)\n",
      "dance_electronic_on-demand_combined.csv: 14544 -> 14400 rows (change: -144)\n",
      "heatseekers_combined.csv: 10944 -> 10800 rows (change: -144)\n",
      "pop_on-demand_streaming_combined.csv: 14544 -> 14400 rows (change: -144)\n",
      "r&b_hip_hop_airplay_combined.csv: 14846 -> 14702 rows (change: -144)\n",
      "r&b_hip_hop_albums_combined.csv: 204 -> 202 rows (change: -2)\n",
      "r&b_hip_hop_on-demand_streaming_combined.csv: 202 -> 200 rows (change: -2)\n",
      "rock_airplay_combined.csv: 15600 -> 15456 rows (change: -144)\n",
      "rock_on-demand_streaming_combined.csv: 14544 -> 14400 rows (change: -144)\n",
      "top_200_song_consumption_combined.csv: 14339 -> 14197 rows (change: -142)\n",
      "top_40_airplay_combined.csv: 14852 -> 14708 rows (change: -144)\n",
      "video_on-demand_streaming_combined.csv: 14544 -> 14400 rows (change: -144)\n"
     ]
    }
   ],
   "source": [
    "# Cleaning all the combined files\n",
    "\n",
    "def clean_csv_files_to_new_folder_with_row_changes(source_folder, destination_folder):\n",
    "    # Ensure the destination folder exists\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Track changes in row counts\n",
    "    row_changes = []\n",
    "\n",
    "    # Iterate through all CSV files in the source folder\n",
    "    for filename in os.listdir(source_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            source_file_path = os.path.join(source_folder, filename)\n",
    "\n",
    "            # Modify the filename to replace '_combined.csv' with '_cleaned.csv'\n",
    "            new_filename = filename.replace('_combined.csv', '_cleaned.csv')\n",
    "            destination_file_path = os.path.join(destination_folder, new_filename)\n",
    "\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(source_file_path)\n",
    "\n",
    "            # Record the initial number of rows\n",
    "            initial_row_count = df.shape[0]\n",
    "\n",
    "            # Set the first row as the header\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df[1:]  # Drop the first row since it's now the header\n",
    "\n",
    "            # Rename the last column to \"week_of\"\n",
    "            df.columns = [*df.columns[:-1], \"week_of\"]\n",
    "\n",
    "            # Drop rows where the first column starts with 'Copyright'\n",
    "            df = df[~df.iloc[:, 0].astype(str).str.startswith('Copyright')]\n",
    "\n",
    "            # Remove rows where the \"Rank\" column doesn't contain a number\n",
    "            if \"Rank\" in df.columns:\n",
    "                df = df[df[\"Rank\"].apply(lambda x: str(x).isdigit())]\n",
    "\n",
    "            # Record the final number of rows\n",
    "            final_row_count = df.shape[0]\n",
    "\n",
    "            # Save the cleaned CSV to the destination folder\n",
    "            df.to_csv(destination_file_path, index=False)\n",
    "            print(f\"Cleaned file saved: {destination_file_path}\")\n",
    "\n",
    "            # Append the row change to the list\n",
    "            row_changes.append((filename, initial_row_count, final_row_count))\n",
    "\n",
    "    # Print the row changes for each file\n",
    "    print(\"\\nRow Changes Summary:\")\n",
    "    for filename, initial, final in row_changes:\n",
    "        print(f\"{filename}: {initial} -> {final} rows (change: {final - initial})\")\n",
    "\n",
    "# Usage\n",
    "source_folder = \"../../data/beema/combined_data_beema\"\n",
    "destination_folder = \"../../data/beema/cleaned_data_beema\"\n",
    "clean_csv_files_to_new_folder_with_row_changes(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Sizes:\n",
      "billboard_200_cleaned.csv: 2043.65 KB\n",
      "country_airplay_cleaned.csv: 1226.83 KB\n",
      "country_on-demand_streaming_cleaned.csv: 1899.53 KB\n",
      "current_country_albums_cleaned.csv: 514.99 KB\n",
      "current_pop_albums_cleaned.csv: 674.10 KB\n",
      "current_r&b_hip_hop_albums_cleaned.csv: 1265.75 KB\n",
      "current_rap_albums_cleaned.csv: 646.17 KB\n",
      "current_rock_albums_cleaned.csv: 330.28 KB\n",
      "dance_electronic_on-demand_cleaned.csv: 1781.36 KB\n",
      "heatseekers_cleaned.csv: 1082.05 KB\n",
      "pop_on-demand_streaming_cleaned.csv: 1853.75 KB\n",
      "r&b_hip_hop_airplay_cleaned.csv: 1207.20 KB\n",
      "r&b_hip_hop_albums_cleaned.csv: 18.29 KB\n",
      "r&b_hip_hop_on-demand_streaming_cleaned.csv: 25.29 KB\n",
      "rock_airplay_cleaned.csv: 1139.94 KB\n",
      "rock_on-demand_streaming_cleaned.csv: 1819.26 KB\n",
      "top_200_song_consumption_cleaned.csv: 1894.47 KB\n",
      "top_40_airplay_cleaned.csv: 1187.80 KB\n",
      "video_on-demand_streaming_cleaned.csv: 1563.24 KB\n",
      "\n",
      "Total Size: 22173.96 KB (21.65 MB)\n"
     ]
    }
   ],
   "source": [
    "## Looking at file sizes and total size of cleaned data\n",
    "\n",
    "def get_file_sizes(folder_path):\n",
    "    total_size = 0\n",
    "    file_sizes = []\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            # Get the size of the file\n",
    "            size = os.path.getsize(file_path)\n",
    "            total_size += size\n",
    "            file_sizes.append((filename, size))\n",
    "    \n",
    "    # Print individual file sizes\n",
    "    print(\"File Sizes:\")\n",
    "    for filename, size in file_sizes:\n",
    "        print(f\"{filename}: {size / 1024:.2f} KB\")\n",
    "\n",
    "    # Print total size\n",
    "    print(f\"\\nTotal Size: {total_size / 1024:.2f} KB ({total_size / (1024 * 1024):.2f} MB)\")\n",
    "\n",
    "# Usage\n",
    "folder = \"../../data/beema/cleaned_data_beema\"\n",
    "get_file_sizes(folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
